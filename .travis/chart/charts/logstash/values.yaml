replicaCount: 1

updateStrategy:
  type: RollingUpdate

terminationGracePeriodSeconds: 10

image:
  repository: docker.elastic.co/logstash/logstash-oss
  tag: 6.6.1
  pullPolicy: IfNotPresent

nameOverride: "logstash"
fullnameOverride: "logstash"

namespace: "salt-provisioning"

service:
  type: ClusterIP
  annotations: {}
  ports:
    - name: syslog-udp
      port: 1514
      targetPort: syslog-udp
      protocol: UDP
    - name: beats
      port: 5044
      targetPort: beats
      protocol: TCP

ports:
  - name: syslog-udp
    containerPort: 1514
    protocol: UDP
  - name: beats
    containerPort: 5044
    protocol: TCP

resources: {}

priorityClassName: ""

nodeSelector: {}

tolerations: []

securityContext:
  fsGroup: 1000
  runAsUser: 1000

affinity: {}
  # podAntiAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     - topologyKey: "kubernetes.io/hostname"
  #       labelSelector:
  #         matchLabels:
#           release: logstash

podAnnotations: {}
  # iam.amazonaws.com/role: "logstash-role"
  # prometheus.io/scrape: "true"
  # prometheus.io/path: "/metrics"
  # prometheus.io/port: "9198"

podLabels: {}
  # team: "developers"
# service: "logstash"

livenessProbe:
  httpGet:
    path: /
    port: monitor
  initialDelaySeconds: 20
  # periodSeconds: 30
  # timeoutSeconds: 30
  # failureThreshold: 6
  # successThreshold: 1

readinessProbe:
  httpGet:
    path: /
    port: monitor
  initialDelaySeconds: 20
  # periodSeconds: 30
  # timeoutSeconds: 30
  # failureThreshold: 6
  # successThreshold: 1

persistence:
  enabled: false
  ## logstash data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # storageClass: "-"
  accessMode: ReadWriteOnce
  size: 128Mi

volumeMounts:
  - name: data
    mountPath: /usr/share/logstash/data
  - name: patterns
    mountPath: /usr/share/logstash/patterns
  - name: pipeline
    mountPath: /usr/share/logstash/pipeline

volumes: []
  # - name: tls
  #   secret:
  #     secretName: logstash-tls
  # - name: pipeline
  #   configMap:
  #     name: logstash-pipeline
  # - name: certs
  #   hostPath:
  #     path: /tmp

exporter:
  logstash:
    enabled: false
    image:
      repository: bonniernews/logstash_exporter
      tag: v0.1.2
      pullPolicy: IfNotPresent
    env: {}
    resources: {}
    path: /metrics
    port: 9198
    target:
      port: 9600
      path: /metrics
    livenessProbe:
      httpGet:
        path: /metrics
        port: ls-exporter
      periodSeconds: 15
      timeoutSeconds: 60
      failureThreshold: 8
      successThreshold: 1
    readinessProbe:
      httpGet:
        path: /metrics
        port: ls-exporter
      periodSeconds: 15
      timeoutSeconds: 60
      failureThreshold: 8
      successThreshold: 1

elasticsearch:
  host: elasticsearch-client.default.svc.cluster.local
  port: 9200

## ref: https://github.com/elastic/logstash-docker/blob/master/build/logstash/env2yaml/env2yaml.go
config:
  config.reload.automatic: "true"
  path.config: /usr/share/logstash/pipeline
  path.data: /usr/share/logstash/data

  ## ref: https://www.elastic.co/guide/en/logstash/current/persistent-queues.html
  queue.checkpoint.writes: 1
  queue.drain: "true"
  queue.max_bytes: 1gb  # disk capacity must be greater than the value of `queue.max_bytes`
  queue.type: persisted

## Patterns for filters.
## Each YAML heredoc will become a separate pattern file.
patterns:
# main: |-
#   TESTING {"foo":.*}$

## NOTE: To achieve multiple pipelines with this chart, current best practice
## is to maintain one pipeline per chart release. In this way configuration is
## simplified and pipelines are more isolated from one another.

inputs:
  main: |-
    input {
      udp {
        port => 1514
        codec => json
      }
    }

filters:
# main: |-
#   filter {
#   }

outputs:
  main: |-
    output {
      stdout { codec => json }
      #elasticsearch {
      #  hosts => ["${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}"]
      #  manage_template => false
      #  index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
      #  document_type => "%{[@metadata][type]}"
      #}
    }
